---
title: استفاده از مدل‌های اولاما در ابسیدین
aliases:
  - استفاده از مدل‌های اولاما در ابسیدین
date: 2024-09-12
draft: false
status: 🌿درختچه
parent: "[[obsidian|🔮 نرم‌افزار ابسیدین]]"
hierarchy: "5"
image: ollama.svg
tags: 
description:
---
در دنیای امروز، هوش مصنوعی در حوزه‌های مختلف مانند تولید محتوا، تحلیل داده‌ها و خلاصه‌سازی به کار گرفته می‌شود. اگر از نرم‌افزار ابسیدین استفاده می‌کنید می‌توانید مستقیما در محیط آن با هوش مصنوعی تعامل کرده و از مدل‌های زبانی برای تولید محتوا و تحلیل داده کمک بگیرید.

برای استفاده از هوش مصنوعی در ابسیدین، سرویس‌های مختلفی در دسترس هستند. یکی از سرویس‌های محبوب و رایگان، Ollama است که به کمک آن می‌توانید مدل‌های زبانی بزرگ را روی سیستم خود اجرا کنید. در ادامه یاد می‌گیرید که چگونه این سرویس را نصب کرده و از طریق پلاگین‌های مختلف با آن ارتباط برقرار کنید.

<br/>

## درمورد Ollama
اگر قصد دارید مدل‌های زبانی بزرگ (LLM) را روی سیستم خود اجرا کنید، یکی از راحت‌ترین روش‌ها استفاده از پلتفرم Ollama است. **اولاما** یک پلتفرم اوپن‌سورس است که به شما اجازه می‌دهد بدون نیاز به سرور‌های قوی یا دانش فنی، مدل‌های زبانی مختلف را به راحتی دانلود، نصب و استفاده کنید.


 استفاده از **اولاما** رایگان است و شما بدون هیچ هزینه یا محدودیتی می‌توانید از مدل‌های زبانی مختلف استفاده کنید. 
 
 این پلتفرم امنیت بالایی دارد. اگر اطلاعات خصوصی یا حساسی دارید که نمی خواهید با دیگران به اشتراک بگذارید استفاده از این روش گزینه مناسبی است. چون بر خلاف سرویس‌هایی مثل چتGPT که اطلاعات شما به سرورهای آن ارسال می شوند، در **اولاما** مدل های زبانی مستقیما روی سیستم شما نصب شده و بدون نیاز به اینترنت اجرا می شوند. به این ترتیب اطمینان دارید که اطلاعات شما تحت هیچ شرایطی به سرورهای خارجی ارسال نخواهد شد.

<br/><br/>

## راهنمای نصب ollama
### گام اول: نصب اولاما
برای استفاده از مدل‌های زبانی اول باید اولاما رو نصب کنید. به سایت [ollama.com](https://ollama.com/) رفته و نسخه مناسب با سیستم عامل خود را دانلود و نصب کنید. (نصب آن آسان است و تنظیم خاصی ندارد)
![[Screenshot113613.webp]]

بعد از نصب، آیکون برنامه به منوی start ویندوز اضافه می‌شود. روی آن کلیک کنید تا اجرا شود. بعد از کلیک صفحه خاصی باز نمی شود، فقط اولاما در حالت اجرا قرار گرفته و آیکون برنامه در نوار وظیفه ویندوز اضافه می‌شود.
![[Pasted image 20240911115136.png|200]]

<br/><br/>

### گام دوم: نصب مدل‌ها
بعد از نصب، باید مدل زبانی مدنظر خود را دانلود کنید. در [ollama.com/library](https://ollama.com/library "ollama model library") می توانید فهرست همه مدل ها را مشاهده کنید. در [صفحه گیت هاب اولاما](https://github.com/ollama/ollama) یک جدول وجود دارد که حجم و مقدار پارامتر هر مدل را توضیح داده است.

![[Screenshot112438.webp]]

طبق توضیح اولاما برای مدل‌های 7B باید حداقل 8 گیگ رم، مدل‌های 13B حداقل 16 گیگ رم و مدل‌های 33B حداقل 32 گیگ رم داشته باشید. هر چه قدر حجم مدل بیشتر باشد پردازش آن هم طولانی‌تر می‌شود. اگر سیستم قوی ندارید، از مدل‌های کوچک‌تر استفاده کنید.

مدل خود را انتخاب کرده و به صفحه مخصوص آن بروید. مثلا من قصد دارم مدل [llama3.1](https://ollama.com/library/llama3.1) را اجرا کنم.
![[llama3.1.webp]]
 
 برای دانلود مدل کافیست کامند `ollama run llama3.1` را در ترمینال وارد کنید. بعد از تکمیل دانلود مدل آماده اجرا است و در همان ترمینال میتوانید با آن چت کنید.
 ![[Pasted image 20240911201143.png|500]]
 طبیعتا چت کردن با مدل در این محیط جذاب و راحت نیست. به همین خاطر ما قصد داریم در گام بعدی با کمک پلاگین‌های مختلف از این مدل در محیط نرم‌افزار ابسیدین استفاده کنیم. البته می‌توانید از روش‌های دیگر نیز برای ارتباط با این مدل استفاده کنید. به عنوان مثال، با نصب [Open WebUI](https://github.com/open-webui/open-webui) می‌توانید از محیطی مشابه ChatGPT برای چت کردن با این مدل استفاده کنید.

 > [!tip] دستورات دیگر
 > 
> برای مشاهده مدل‌های نصب شده می توانید از دستور `ollama list` و برای دیدن مدل در حال اجرا از دستور `ollama ps` استفاده کنید.
> 
> مدل های دانلود شده در مسیر `C:\Users\%username%\.ollama\models` قرار می‌گیرند. برای حذف مدل‌های نصب شده به جای حذف آنها از این پوشه بهتر است از دستور `ollama rm model-name` استفاده کنید.
> 
> موارد بیشتر را می توانید در [سوالات متداول](https://github.com/ollama/ollama/blob/main/docs/faq.md) مطالعه کنید.

<br/>

بعضی از مدل‌ها تقریبا از زبان فارسی پشتیبانی می‌کنند و اگر پرامپت فارسی بنویسید پاسخ شما را به زبان فارسی می‌نویسند. مدل [llama3.1](https://ollama.com/library/llama3.1) و  [gemma2](https://ollama.com/library/gemma2) نسبتا خوب است. مدل [qwen2](https://ollama.com/library/qwen2) هم معمولی است. مدل [phi3](https://ollama.com/library/phi3) تا جایی که من تست کردم از زبان فارسی پشتیبانی نکرد.

یک مدل هم هست به اسم [dorna-llama3](https://ollama.com/partai/dorna-llama3) که توسط «مرکز تحقیقات هوش مصنوعی پارت» بر روی داده های فارسی آموزش دیده است.([+](https://partdp.ai/blog/dorna/))  حجم مدل درنا دو برابر مدل اصلی است. مدل اصلی 4.7 گیگ ولی مدل درنا 8.5 گیگ است، به خاطر همین سرعت پایین تری دارد. در یادداشت [[llama vs dorna|مقایسه مدل اصلی llama3 با مدل dorna]] اجمالا این دو مدل را بررسی کردم که مدل جدید llama3.1 عملکرد بهتری دارد.

<br/><br/>

## استفاده در ابسیدین
پلاگین‌های مختلفی برای استفاده از اولاما در ابسیدین وجود دارد. در این جا به چند مورد اشاره می‌کنم.

<br/>

### پلاگین Local GPT
پلاگین [Local GPT](https://github.com/pfrankov/obsidian-local-gpt) یک افزونه ساده است که داخل خود یادداشت‌ اجرا می شود. یک منوی ساده دارد که می توانید اقدامات مختلف را برای آن تعریف کنید.

استفاده از این روش بسیار راحت است و بدون نیاز به ترمنیال انجام می شود:

۱. به مخزن پلاگین ها رفته و [Local GPT](https://obsidian.md/plugins?id=local-gpt)را نصب کنید.

۲. بعد از فعال‌سازی به تنظیمات پلاگین رفته و از بخش configure Ai اولاما را انتخاب کنید. روی رفرش بزنید تا مدل های نصب شده لیست شود. (مطمئن شوید که اولاما در حال اجرا است، از منوی start روی آیکون ollama کلیک کنید تا به نوار وظیفه ویندوز اضافه شود)

۳. بعد از انتخاب مدل به قسمت Hotkeys رفته و عبارت Local GPT را سرچ کنید. یک کلید میانبر برای `Local GPT: show context menu` وارد کنید. مثلا `Ctrl + m`. 

۴. حالا یک یادداشت جدید ایجاد کنید. متن پرامپت خود را بنوسید. متن را سلکت کنید و `Ctrl + m` را بزنید. از منوی باز شده General help را انتخاب کنید. مدل اجرا می شود و پاسخ شما را در همان صفحه می نویسد.

![demo](https://github.com/pfrankov/obsidian-local-gpt/assets/584632/724d4399-cb6c-4531-9f04-a1e5df2e3dad)

همانطور که مشاهده کردید در منوی باز شده علاوه بر جنریت معمولی چند حالت پیشفرض هم در این پلاگین قرار دارد که میتوانید برای تولید محتوا، خلاصه‌سازی، تصحیح املا و پیدا کردن تسک‌ استفاده کنید. در تنظیمات پلاگین از بخش Action list  میتوانید این موارد را ویرایش کنید. 

![[Screenshot121544.webp|550]]

روی ادیت بزنید. اینجا دو فیلد را باید تکمیل کنید:

- **فیلد System prompt:** اینجا به مدل دستور می دهید که خودش را چگونه فرض کند. مثلا: «فرض کن تو یک دستیار هستی»، «فرض کن تو یک ویراستار هستی»، «فرض کن تو یک آشپز هستی».

- **فیلد Prompt:** اینجا پرامپت خود را مشخص می کنیم. مثلا: «متن زیر را خلاصه کن»، «متن زیر را بازنویسی کن».

متن سلکت شده شما بعد از این پرامپت قرار می‌گیرد. البته می‌توانید با قرار دادن عبارت `{{=SELECTION=}}` در فیلد Prompt یک جایگاه سفارشی برای متن انتخاب شده تعریف کنید. مثلا دستور زیر جواب مدل را در کالوت قرار می دهد:
```
متن زیر را با تغییر کلمات و ساختار جمله بازنویسی کن:
>[!NOTE] عنوان
>{{=SELECTION=}}
```

از بخش Add new manually هم می‌توانید اقدامات سفارشی خود را اضافه کنید. مثلاً من یک مورد را برای اصلاح نیم‌فاصله اضافه کردم.
![[Screenshot222956.webp]]

<br/>

> [!abstract] بررسی پلاگین
> **امکانات**
> - نصب و سریع و راحت.
> - ساخت اکشن و تعریف پرامپت از پیش تعریف شده.
> - استفاده مستقیم در متن یادداشت.
> - امکان استفاده از مدل‌های زبانی بزرگ و هوش مصنوعی open Ai.
> - خواندن و توصیف تصاویر.
> 
> ---
> 
> **محدودیت ها**
> - عدم ذخیره چت: این پلاگین چت‌ها را ذخیره نمی کند و نمی توانید در فرصت دیگری مکالمه را ادامه دهید. حتی پرامپت قبلی را هم نمی توانید ادامه دهید. هر کدام مستقلا عمل می کنند.
> - عدم دسترسی به والت: نمی توانید والت خود را به عنوان منبع در اختیار مدل قرار داده تا پاسخ سوالات را بر اساس یادداشت های‌تان بنویسد.

<br/><br/>

### پلاگین Smart Second Brain
پلاگین [Smart Second Brain](https://github.com/your-papa/obsidian-Smart2Brain) یکی دیگر از افزونه هایی است که به شما اجازه میدهد از مدل های زبانی هوش مصنوعی استفاده کنید.

از نقاط قوت اصلی این پلاگین، قابلیت اتصال مستقیم به یادداشت‌های شماست. برخلاف بسیاری از ابزارهای هوش مصنوعی که فقط از اطلاعات عمومی یا داده‌های از پیش تعریف‌شده استفاده می‌کنند، این پلاگین اجازه می‌دهد والت خود را به عنوان منبع پاسخ‌دهی انتخاب کنید.

به این ترتیب دستیار مجازی شما نه تنها می‌تواند از اطلاعات عمومی استفاده کند، بلکه به یادداشت‌های شما هم دسترسی دارد و قادر است آن‌ها را تجزیه و تحلیل کند. این قابلیت به شما کمک می‌کند که پاسخ‌هایی کاملاً شخصی‌سازی شده و مبتنی بر محتوای خاصی که خودتان نوشته‌اید، دریافت کنید.

![image|600](https://github.com/your-papa/obsidian-Smart2Brain/assets/48623649/9948671a-ebc4-4315-b376-0918c6f7f4f8)

<br/>

> [!info] آموزش استفاده
> 
> آموزش استفاده از این پلاگین را می توانید در این لینک مشاهده کنید: [Smart Second Brain for Obsidian](https://youtu.be/QS1oobyRLCI?si=L0yg29BCGz7Jentb)

> [!abstract] بررسی پلاگین
> **امکانات**
> - امکان انتخاب والت به عنوان منبع برای پاسخ دهی.
> - ذخیره سابقه چت.
> - رابط کاربری مناسب.
> - امکان استفاده از مدل های زبانی بزرگ و هوش مصنوعی open Ai
> 
> ---
> **محدودیت‌ها**
> - پشتیبانی ضعیف از زبان فارسی.
> - پردازش سنگین و طولانی.
> - محدودیت مکالمه: بعد از سه چهار مرتبه چت کردن اخطار می دهد که چت طولانی شده و باید یک مکالمه جدید را شروع کنید.

<br/><br/>

### پلاگین Copilot
پلاگین [Copilot](https://github.com/logancyang/obsidian-copilot) هم یک افزونه ساده و مینیمال است که می توانید در ابسیدین از آن استفاده کنید. (این پلاگین ارتباطی به هوش مصنوعی کوپایلوت مایکروسافت ندارد) این پلاگین هم تقریبا مشابه پلاگین قبلی است. می‌توانید والت خود را به عنوان منبع پاسخ دهی انتخاب کنید. در این پلاگین علاوه بر مدل های زبانی می‌توانید از اکثر هوش مصنوعی های مختلف مثل OpenAI, Azure, Google Gemini, Claude استفاده کنید.

![image](https://raw.githubusercontent.com/logancyang/obsidian-copilot/master/images/ui.png)

<br/>

> [!info] آموزش استفاده
> آموزش استفاده از این پلاگین را می توانید در این لینک مشاهده کنید: [Obsidian with Ollama](https://www.youtube.com/watch?v=9YYB8a_ehc4&t=2s)
> 

> [!abstract] بررسی پلاگین
> **امکانات**
> - امکان انتخاب والت به عنوان منبع برای پاسخ دهی.
> - ذخیره سابقه چت.
> - رابط کاربری مناسب.
> - امکان استفاده از مدل های ollama و هوش مصنوعی های مختلف مانند open Ai
> 
> ---
> **محدودیت‌ها**
> - پشتیبانی ضعیف از زبان فارسی.

<br/><br/>

---


**توضیحات بیشتر:**
- [شروع راه برنامه‌نویسی جی پی تی و مدل‌های زبانی بزرگ](https://www.youtube.com/watch?v=FRRndyC3kyM&t=1277s)