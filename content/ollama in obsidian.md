---
title: استفاده از مدل‌های اولاما در ابسیدین
aliases:
  - استفاده از مدل‌های اولاما در ابسیدین
date: 2024-09-12
draft: false
status: 🌱نهال
parent: "[[obsidian|🔮 نرم‌افزار ابسیدین]]"
hierarchy: "5"
image: ollama.svg
tags: 
description:
---

در دنیای امروز، استفاده از هوش مصنوعی در زمینه‌هایی مانند تولید محتوا، تحلیل داده و خلاصه‌سازی به سرعت در حال افزایش است. اگر از نرم افزار ابسیدین استفاده می کنید می توانید مستقیما در محیط آن با هوش مصنوعی تعامل کرده و از مدل‌های زبانی برای تولید محتوا و تحلیل داده‌ها کمک بگیرید.

برای استفاده از هوش مصنوعی در ابسیدین، سرویس‌های مختلفی در دسترس هستند. یکی از سرویس‌های محبوب و رایگان، Ollama است.  در ادامه یاد می‌گیرید چه طور آن را نصب کرده و با استفاده از پلاگین‌های مختلف با آن تعامل کنید.

<br/>

## درمورد Ollama
اگر قصد دارید مدل‌های زبانی بزرگ (LLM) را روی سیستم خود اجرا کنید، یکی از راحت‌ترین روش‌ها استفاده از پلتفرم Ollama است. **اولاما** یک پلتفرم اوپن‌سورس است که به شما اجازه می‌دهد بدون نیاز به سرور‌های قوی یا دانش فنی، مدل‌های زبانی مختلف را به راحتی دانلود، نصب و استفاده کنید.


 استفاده از **اولاما** رایگان است و شما بدون هیچ هزینه یا محدودیتی می‌توانید از مدل‌های زبانی مختلف استفاده کنید. 
 
 این پلتفرم امنیت بالایی دارد. اگر اطلاعات خصوصی یا حساسی دارید که نمی خواهید با دیگران به اشتراک بگذارید استفاده از این روش گزینه مناسبی است. چون بر خلاف سرویس‌هایی مثل چتGPT که اطلاعات شما به سرورهای آن ارسال می شوند، در **اولاما** مدل های زبانی مستقیما روی سیستم شما نصب شده و بدون نیاز به اینترنت اجرا می شوند. به این ترتیب اطمینان دارید که اطلاعات شما تحت هیچ شرایطی به سرورهای خارجی ارسال نخواهد شد.

<br/><br/>

## راهنمای نصب ollama
### گام اول: نصب اولاما
برای استفاده از مدل‌های زبانی اول باید اولاما رو نصب کنید. به سایت [ollama.com](https://ollama.com/) رفته و نسخه مناسب با سیستم عامل خود را دانلود و نصب کنید. (نصب آن آسان است و تنظیم خاصی ندارد)
![[Screenshot113613.webp]]

بعد از نصب، آیکون برنامه به منوی start ویندوز اضافه می‌شود. روی آن کلیک کنید تا اجرا شود. بعد از کلیک صفحه خاصی باز نمی شود، فقط اولاما در حالت اجرا قرار گرفته و آیکون برنامه در نوار وظیفه ویندوز اضافه می‌شود.
![[Pasted image 20240911115136.png|200]]

<br/><br/>

### گام دوم: نصب مدل‌ها
بعد از نصب، باید مدل زبانی مدنظر خود را دانلود کنید. در [ollama.com/library](https://ollama.com/library "ollama model library") می توانید فهرست همه مدل ها را مشاهده کنید. در [صفحه گیت هاب اولاما](https://github.com/ollama/ollama) یک جدول وجود دارد که حجم و مقدار پارامتر هر مدل را توضیح داده.

![[Screenshot112438.webp]]

طبق توضیح اولاما برای مدل های 7B باید حداقل 8 گیگ رم، مدل های 13B حداقل 16 گیگ رم و مدل های 33B حداقل 32 گیگ رم داشته باشید. هر چه قدر حجم مدل بیشتر باشد پردازش آن هم طولانی‌تر می‌شود. اگر سیستم قوی ندارید، از مدل‌های کوچک‌تر استفاده کنید.

مدل خود را انتخاب کرده و به صفحه مخصوص آن بروید. مثلا من قصد دارم مدل [llama3.1](https://ollama.com/library/llama3.1) را اجرا کنم.
![[llama3.1.webp]]
 
 برای دانلود مدل کافیست کامند `ollama run llama3.1` را در ترمینال وارد کنید. بعد از تکمیل دانلود مدل آماده اجرا است و در همان ترمینال میتوانید با آن چت کنید. 
 ![[Pasted image 20240911201143.png|500]]
 طبیعتا تعامل کردن در این محیط جذاب نیست. به همین خاطر ما قصد داریم در گام بعدی با کمک پلاگین های مختلف از این مدل در ابسیدین استفاده کنیم. می‌توانید از روش‌های دیگر نیز برای ارتباط با این مدل استفاده کنید. به عنوان مثال، با نصب [Open WebUI](https://github.com/open-webui/open-webui) می‌توانید از محیطی مشابه ChatGPT برای چت کردن با این مدل استفاده کنید.

 > [!tip] دستورات دیگر
 > 
> برای مشاهده مدل‌های نصب شده می توانید از دستور `ollama list` و برای دیدن مدل در حال اجرا از دستور `ollama ps` استفاده کنید.
> 
> مدل های دانلود شده هم در مسیر زیر قرار می‌گیرند.
> Windows: `C:\Users\%username%\.ollama\models`
> 
> موارد بیشتر را می توانید در [سوالات متداول](https://github.com/ollama/ollama/blob/main/docs/faq.md) مطالعه کنید.

<br/>

مدل های اولاما تقریبا از زبان فارسی پشتیبانی می‌کنند و اگر پرامپت فارسی بنویسید پاسخ شما را به زبان فارسی می نویسد. مدل [llama3.1](https://ollama.com/library/llama3.1) و  [gemma2](https://ollama.com/library/gemma2) نسبتا خوب است. مدل [qwen2](https://ollama.com/library/qwen2) هم معمولی است. مدل [phi3](https://ollama.com/library/phi3) تا جایی که من تست کردم از زبان فارسی پشتیبانی نکرد.

یک مدل هم هست به اسم [dorna-llama3](https://ollama.com/partai/dorna-llama3) که توسط «مرکز تحقیقات هوش مصنوعی پارت» بر روی داده های فارسی آموزش دیده است.([+](https://partdp.ai/blog/dorna/))  حجم مدل درنا دو برابر مدل اصلی است. مدل اصلی 4.7 گیگ ولی مدل درنا 8.5 گیگ است، به خاطر همین سرعت پایین تری دارد. در یادداشت [[llama vs dorna|مقایسه مدل اصلی llama3.1 با مدل dorna]] اجمالا این دو مدل را بررسی کردم که ظاهرا مدل اصلی عملکرد بهتری دارد.

<br/><br/>

## استفاده در ابسیدین
پلاگین‌های مختلفی برای استفاده از اولاما در ابسیدین وجود دارد. در این جا به چند مورد اشاره می‌کنم.

<br/>

### پلاگین Local GPT
استفاده از این روش بسیار راحت است و بدون نیاز به ترمنیال انجام می شود:

۱. به مخزن پلاگین ها رفته و [Local GPT](https://obsidian.md/plugins?id=local-gpt)را نصب کنید.

۲. بعد از فعال‌سازی به تنظیمات پلاگین رفته و از بخش configure Ai اولاما را انتخاب کنید. روی رفرش بزنید تا مدل های نصب شده لیست شود. (مطمئن شوید که اولاما در حال اجرا است، از منوی start روی آیکون ollama کلیک کنید تا به نوار وظیفه ویندوز اضافه شود)

۳. بعد از انتخاب مدل به قسمت Hotkeys رفته و عبارت Local GPT را سرچ کنید. یک کلید میانبر برای `Local GPT: show context menu` وارد کنید. مثلا `Ctrl + m`. 

۴. حالا یک یادداشت جدید ایجاد کنید. متن پرامپت خود را بنوسید. متن را سلکت کنید و `Ctrl + m` را بزنید. از منوی باز شده General help را انتخاب کنید. مدل اجرا می شود و پاسخ شما را در همان صفحه می نویسد.

![demo](https://github.com/pfrankov/obsidian-local-gpt/assets/584632/724d4399-cb6c-4531-9f04-a1e5df2e3dad)


> [!example] اکشن‌ها
> 
> همانطور که مشاهده کردید در منوی باز شده علاوه بر جنریت معمولی چند حالت پیشفرض هم در این پلاگین قرار دارد که میتوانید برای تولید محتوا، خلاصه‌سازی، تصحیح املا و پیدا کردن تسک‌ استفاده کنید. در تنظیمات پلاگین از بخش Action list  میتوانید این موارد را ویرایش کنید. 
> 
> ![[Screenshot121544.webp|550]]
> 
> روی ادیت بزنید. اینجا دو فیلد را باید تکمیل کنید:
> 
> - **فیلد System prompt:** اینجا به مدل دستور می دهید که خودش را چگونه فرض کند. مثلا: «فرض کن تو یک دستیار هستی»، «فرض کن تو یک ویراستار هستی»، «فرض کن تو یک آشپز هستی».
> 
> - **فیلد Prompt:** اینجا پرامپت خود را مشخص می کنیم. مثلا: «متن زیر را خلاصه کن»، «متن زیر را بازنویسی کن».
> 
> متن سلکت شده شما بعد از این پرامپت قرار می‌گیرد. البته می‌توانید با قرار دادن عبارت `{{=SELECTION=}}` در فیلد Prompt یک جایگاه سفارشی برای متن انتخاب شده تعریف کنید. مثلا دستور زیر جواب مدل را در کالوت قرار می دهد:
> ```
> متن زیر را با تغییر کلمات و ساختار جمله بازنویسی کن:
> >[!NOTE] عنوان
> >{{=SELECTION=}}
>```
>
> از بخش Add new manually هم میتوانید اقدامات سفارشی خود را اضافه کنید.

<br/>

باقی موارد در آینده تکمیل می شود...

<br/>

### پلاگین Smart Second Brain
https://github.com/your-papa/obsidian-Smart2Brain

<br/>

### پلاگین Copilot

https://github.com/logancyang/obsidian-copilot

<br/>

### پلاگین BMO Chatbot
https://github.com/longy2k/obsidian-bmo-chatbot


<br/><br/>

**توضیحات بیشتر:**
- [شروع راه برنامه‌نویسی جی پی تی و مدل‌های زبانی بزرگ](https://www.youtube.com/watch?v=FRRndyC3kyM&t=1277s)
- 